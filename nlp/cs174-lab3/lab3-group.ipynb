{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJ5Uy96P_fbb"
   },
   "source": [
    "# Problem Set 3 CS174\n",
    "---\n",
    "The following problem set will focus on the lessons on Bag of Words and TFIDF. Answer the following guide questions with your groups by writing functions or code in cells that accomplish the requirements.\n",
    "\n",
    "1. Take your favorite Spotify or Apple Music playlist, and use their APIs to programmatically extract the first 20 song titles. Build a dictionary that has the song index as the key, and the title as the value. Please make sure that the playlist is **NOT** an instrumental playlist. **3 pts.**\n",
    "\n",
    "2. Use the Genius API to programmatically download the lyrics of these songs and store them in a dictionary with the index as the key, and the lyrics as the value. **3 pts.**\n",
    "\n",
    "3. Build a 20x20 matrix containing the cosine similarities of the songs to each other. Use Bag of Words to determine these similarities. **4 pts.**\n",
    "\n",
    "\n",
    "4. Build a 20x20 matrix containing the cosine similarities of the songs to each other. Use TFIDF scores to determine these similarities. **5 pts.**\n",
    "\n",
    "5. Compare the similarities using BoW and TFIDF. Analyze the results and discuss any findings that interest you. You can use heatmaps or other plots to present your analysis. **3 pts**\n",
    "\n",
    "Guide Questions:\n",
    "- Can this be used to determine playlist quality?\n",
    "- What does this say about the homogeneity of the playlist themes?\n",
    "- What does this say about how songs (in that playlist genre) are written?\n",
    "\n",
    "6. Identify the top 5 most important words for each song using TFIDF. Discuss the relationship of these words to their respective songs and analyze if they can be used as passable summaries of the songs. **2 pts** \n",
    "\n",
    "Make sure to remove stopwords. No need to lemmatize or stem, but is very welcome.\n",
    "       \n",
    "### Bonus:\n",
    "Do a TFIDF analysis for a single artist's top 5 songs. Identify the top 10 most important words and discuss an analysis of these. **5 pts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9V27zAF_lyx"
   },
   "source": [
    "Deadline **March 17 11:59PM**. Submission link to be posted in Moodle. \n",
    "Submit a .zip file containing the notebook and a 'data/' directory containing the songs with name <SURNAME>_<ID NUMBER>.ipynb.\n",
    "Make sure to remove or obfuscate any API keys you include in the final submission.\n",
    "    \n",
    "Sample: **\"BAUTISTA_110464.zip\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2_A46cI_rCq"
   },
   "source": [
    "# 1. Spotify API to extract 20 song titles\n",
    "\n",
    "1. Take your favorite Spotify or Apple Music playlist, and use their APIs to programmatically extract the first 20 song titles. Build a dictionary that has the song index as the key, and the title as the value. Please make sure that the playlist is **NOT** an instrumental playlist. **3 pts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zb1OsP_H9kba"
   },
   "source": [
    "## Setting up Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGszdT1a76he"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "colab-env only works in a Google Colab notebook",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colab_env\\handler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-927e589a064d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install colab-env -qU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcolab_env\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colab_env\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0.2.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcolab_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColabEnvHandler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0menvvar_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColabEnvHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colab_env\\handler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"colab-env only works in a Google Colab notebook\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: colab-env only works in a Google Colab notebook"
     ]
    }
   ],
   "source": [
    "!pip install colab-env -qU\n",
    "import colab_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAezWs168Cka"
   },
   "outputs": [],
   "source": [
    "# To add the Spotify client ID and secret, modify the add_env lines below and uncomment\n",
    "from colab_env import envvar_handler\n",
    "\n",
    "envvar_handler.add_env('SPOTIPY_CLIENT_ID', '8b4ef1fef08a46d1aae4e9f957491aa6')\n",
    "envvar_handler.add_env('SPOTIPY_CLIENT_SECRET', 'e2c07f4c07f743018da06acbd1623009')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdArl3UMFkvc"
   },
   "source": [
    "## Getting the playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "itYy7HdF8kgD",
    "outputId": "e4bd8f14-f881-4106-feaa-f86ee1b4ac93"
   },
   "outputs": [],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TO3d8Ns-Nf8"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Gets the credentials from the environment variables. Make sure that SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET\n",
    "# are in your environment.\n",
    "client_credentials_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQjFVVuKTBrW"
   },
   "outputs": [],
   "source": [
    "# Editing titles (i.e. removing the \"Remastered\" parts of the title)\n",
    "def edit_title(title):\n",
    "  if title == 'You Make My Dreams - Remastered':\n",
    "    return 'You Make My Dreams'\n",
    "  elif title == 'Let It Be - Remastered 2009':\n",
    "    return 'Let It Be'\n",
    "  elif title == \"Don't Stop Me Now - 2011 Mix\":\n",
    "    return \"Don't Stop Me Now\"\n",
    "  else:\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "v3HiGgkq_vUO",
    "outputId": "b6765ba6-a628-4ba9-9c9c-618ecf235c6d"
   },
   "outputs": [],
   "source": [
    "PLAYLIST_URI = 'spotify:playlist:0fLLZQlgUdCUbfiDZ3kJq7'\n",
    "NUM_TRACKS = 20\n",
    "\n",
    "# Will modify the dictionary so as to include the artist as well as the song title.\n",
    "# The structure will be a dictionary of two-element tuples. Example: {1 : ('Take On Me', 'a-ha')}\n",
    "\n",
    "playlist_tracks = sp.playlist_tracks(PLAYLIST_URI)['items']\n",
    "playlist_dict = {}\n",
    "for i, track in enumerate(playlist_tracks[:NUM_TRACKS]):\n",
    "  title = track['track']['name']\n",
    "  title = edit_title(title)\n",
    "  artists = ', '.join([artist['name'] for artist in track['track']['artists']])\n",
    "  playlist_dict[i] = (title, artists)\n",
    "\n",
    "print(playlist_dict)\n",
    "songtitles = [playlist_dict[x][0] for x in playlist_dict]\n",
    "songtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fseLkiPqS7d"
   },
   "source": [
    "## 2. Retrieving Lyrics from Genius\n",
    "We obtain the lyrics of songs in the Spotify playlist using the Genius API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FcUoIdnqnhZ"
   },
   "outputs": [],
   "source": [
    "dummy_song = ['Sun goes down, sun comes up\\n', 'Days can drown in a plastic cup\\n', 'In this town\\n', 'In this town\\n', '\\n', \"Don't know how, don't know when\\n\", 'Something came but it left again\\n', \"And I'm down\\n\", 'On this town\\n', '\\n', \"'Cause no matter what I see\\n\", 'People love to disagree\\n', '\\n', 'Every time I say what I want to be\\n', \"Someone says that's not how it's going to be\\n\", 'Come on, baby, quit your dreaming\\n', 'Grab your things, the train is leaving\\n', 'Time to pick that somewhere you want to go\\n', 'Get there quick or drown in the undertow\\n', 'Come on baby, time is wasting\\n', 'Choose a wheel and get to racing\\n', '\\n', 'Sun goes up and down again\\n', 'Hard to stop feeling broken in\\n', 'And worn down\\n', 'By this town\\n', '\\n', 'All the same\\n', 'You find me here\\n', 'Placing blame and escaping fear and self-doubt\\n', 'And this town\\n', '\\n', 'But no matter where I go\\n', 'People love to tell me, \"No\"\\n', '\\n', 'Every time I say what I want to be\\n', \"Someone says that's not how it's going to be\\n\", 'Come on, baby, quit your dreaming\\n', 'Grab your things, the train is leaving\\n', 'Time to pick that somewhere you want to go\\n', 'Get there quick or drown in the undertow\\n', 'Come on, baby, time is wasting\\n', 'Choose a wheel and get to racing\\n', '\\n', 'Every time I say what I want to be\\n', \"Someone says that's not how it's going to be\\n\", 'Come on baby, quit your dreaming\\n', 'Grab your things, the train is leaving\\n', 'And if you feel like nobody understands\\n', 'You just smile and pray that they clap their hands\\n', 'Come on, baby, drown your sorrow\\n', 'Work today and live tomorrow\\n', 'Time to pick that somewhere you want to go\\n', 'Get there quick or drown in the undertow\\n', 'Come on baby, time is wasting\\n', 'Choose a wheel and get to racing ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "IamjpiKo9n-n",
    "outputId": "7662310a-b6bb-449d-a9b3-67d7eee263d6"
   },
   "outputs": [],
   "source": [
    "! pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "zqIdQsze9kjq",
    "outputId": "9d634f1d-322a-416e-b4ed-b7bf7e131946"
   },
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "#songs = {'Green Day':'Holiday', 'The All-American Rejects':'Dirty Little Secret', 'Blink-182':'First Date'}\n",
    "songs = playlist_dict\n",
    "lyrics_dict = {}\n",
    "genius = lyricsgenius.Genius(\"lgrmQD5L0EqGrGCqmiXmHvizYtaDYeu5gAn0TRwD3FPEzE1WRL_Y2mBAZTdrMGB-\")\n",
    "\n",
    "for song in songs:\n",
    "    lyric = genius.search_song(songs[song][0], songs[song][1])\n",
    "    #print(lyric.lyrics,\"\\n\")\n",
    "    lyrics_dict[songs[song]] = lyric.lyrics\n",
    "\n",
    "print(lyrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDpy4XAMroVQ"
   },
   "source": [
    "Below this line, we process lyrics data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJAAhy8nsHD-"
   },
   "source": [
    "# Pre-processing\n",
    "The functions in this section take a list of lyrics (assumed to be one line per element) then performs word splitting, normalization (reduce all letters to lowercase), and lemmatization.\n",
    "\n",
    "To make this a list of songs, we simply have one **song** per element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivxLdDvQst3t"
   },
   "source": [
    "Libraries for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YDttP5-FA2ih",
    "outputId": "4a8b91fe-0f49-4764-e69a-5182feb57af2"
   },
   "outputs": [],
   "source": [
    "!pip install -U nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mwl2VqSsq8F"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9PKH4i_s6qk"
   },
   "outputs": [],
   "source": [
    "def lemmatize(word):\n",
    "    res = word.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    return res if not res in stopWords else ''\n",
    "\n",
    "def get_song_lines_from_dict(lyrics_dict):\n",
    "    song_lines = []\n",
    "    for song_line in [lyrics_dict[index].rstrip().split() for index in lyrics_dict if len(lyrics_dict[index].strip()) > 0]:\n",
    "      # Lemmatize using the function, then filter out empty strings.\n",
    "        song_line = list(filter(lambda x: len(x)>0, [lemmatize(word) for word in song_line]))\n",
    "        if len(song_line) > 0:\n",
    "            song_lines.append(song_line)\n",
    "    return song_lines\n",
    "\n",
    "def get_song_lines_from_file(lyrics_file):\n",
    "    with open(lyrics_file, 'r') as lyrics:\n",
    "        song_lines = []\n",
    "        for song_line in [line.rstrip().split() for line in lyrics if len(line.strip()) > 0]:\n",
    "          # Lemmatize using the function, then filter out empty strings.\n",
    "            song_line = list(filter(lambda x: len(x)>0, [lemmatize(word) for word in song_line]))\n",
    "            if len(song_line) > 0:\n",
    "                song_lines.append(song_line)\n",
    "    return song_lines\n",
    "\n",
    "def get_song_lines_from_list(lyrics_list):\n",
    "    song_lines = []\n",
    "    for song_line in [line.rstrip().split() for line in lyrics_list if len(line.strip()) > 0]:\n",
    "      # Lemmatize using the function, then filter out empty strings.\n",
    "        song_line = list(filter(lambda x: len(x)>0, [lemmatize(word) for word in song_line]))\n",
    "        if len(song_line) > 0:\n",
    "            song_lines.append(song_line)\n",
    "    return song_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "vQ75WxgI20EF",
    "outputId": "0bc0a90b-08c7-44f0-cf09-20dcdb35b8e3"
   },
   "outputs": [],
   "source": [
    "lyrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYWQkpM2Y_f0"
   },
   "source": [
    "# Bag-of-words\n",
    "Given a lyrics file, returns the BOW vector representation of each sentence (where sentence can be a line in a song, or an entire song).\n",
    "# Cosine Similarity Matrix\n",
    "Returns a matrix of the pairwise cosine similarities given a set of lyrics vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyDCFc9UY4yP"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(list_of_sentences):\n",
    "    wordset = set([lemmatize(word) for sentence in list_of_sentences for word in sentence if len(lemmatize(word)) > 0])\n",
    "    results = []\n",
    "    for sentence in list_of_sentences:\n",
    "        results.append([1 if word in sentence else 0 for word in wordset])\n",
    "    nicetable = pd.DataFrame(np.array(results), columns=list(wordset))\n",
    "    return results\n",
    "\n",
    "def cosine_similarity_matrix(bow_vectors):\n",
    "    answer_matrix = [[] for i in range(len(bow_vectors))]\n",
    "    for i in range(len(bow_vectors)):\n",
    "      for j in range(len(bow_vectors)):\n",
    "        answer_matrix[i].append(cosine_similarity([bow_vectors[i]], [bow_vectors[j]])[0][0])\n",
    "    return pd.DataFrame(answer_matrix)#, index=songtitles, columns=songtitles)\n",
    "\n",
    "def cosine_similarity_matrix_tfidf(tfidf_df):\n",
    "    answer_matrix = [[] for i in range(len(tfidf_df))]\n",
    "    for i in range(len(tfidf_df)):\n",
    "      for j in range(len(tfidf_df)):\n",
    "        answer_matrix[i].append(cosine_similarity([tfidf_df.iloc[i]], [tfidf_df.iloc[j]])[0][0])\n",
    "\n",
    "    return pd.DataFrame(answer_matrix)#, index=songtitles, columns=songtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NXzs3rR8wrh"
   },
   "outputs": [],
   "source": [
    "lines_from_dict = get_song_lines_from_dict(lyrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "9QT1SUmr-rxK",
    "outputId": "65d52aed-c7b2-43de-b4bb-f024190f077f"
   },
   "outputs": [],
   "source": [
    "testing_vectors = bag_of_words(lines_from_dict)\n",
    "cosine_bow = cosine_similarity_matrix(testing_vectors)\n",
    "cosine_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJuFK7Eaw14O"
   },
   "source": [
    "# TF-IDF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Og7LmdoxV2S"
   },
   "outputs": [],
   "source": [
    "# Get TF of a line.\n",
    "def get_frequencyBoW(unique_words, line):\n",
    "    bow = dict.fromkeys(unique_words, 0)\n",
    "    for word in line:\n",
    "        bow[word] += 1\n",
    "    return bow\n",
    "  \n",
    "def get_TF(dictionary, line):\n",
    "    tf_dict = {}\n",
    "    bow_count = len(line)\n",
    "    for word, count in dictionary.items():\n",
    "        tf_dict[word] = count / float(bow_count)\n",
    "    return tf_dict\n",
    "\n",
    "def idf(documents):\n",
    "    n = len(documents)\n",
    "    idf_dict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "    \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(n / float(val))\n",
    "    return idf_dict\n",
    "\n",
    "def tfidf(song_lines):\n",
    "    unique_words = set()\n",
    "    for song_line in song_lines:\n",
    "        unique_words = unique_words.union(set(song_line))\n",
    "    frequencyBoWs = []\n",
    "    for song_line in song_lines:\n",
    "        frequencyBoWs.append(get_frequencyBoW(unique_words, song_line))\n",
    "    IDFs = idf(frequencyBoWs)\n",
    "    TFIDFs = []\n",
    "    for song_line in song_lines:\n",
    "        frequencyBoW = get_frequencyBoW(unique_words, song_line)\n",
    "        TF = get_TF(frequencyBoW, song_line)\n",
    "        TFIDF = {}\n",
    "        for word, val in TF.items():\n",
    "            TFIDF[word] = val * IDFs[word]\n",
    "        TFIDFs.append(TFIDF)\n",
    "    return pd.DataFrame(TFIDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "q__4GMBW3uqK",
    "outputId": "21defc20-7d68-4ac0-b946-dfcf74395cd9"
   },
   "outputs": [],
   "source": [
    "tfidf_df = tfidf(lines_from_dict)\n",
    "cosine_tfidf = cosine_similarity_matrix_tfidf(tfidf_df)\n",
    "cosine_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XowVizOXSyM"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "O0sgzVx8XUO6",
    "outputId": "2644b4c3-7942-4567-ce76-33f09240766d"
   },
   "outputs": [],
   "source": [
    "# Bag of Words Heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(cosine_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "lKQ7qltjXPGo",
    "outputId": "d76baca8-e114-494c-c592-062fa8f49bde"
   },
   "outputs": [],
   "source": [
    "# TFIDF Heatmap\n",
    "sns.heatmap(cosine_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuYjI-aZV8_"
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "  mn = 1\n",
    "  mx = 0\n",
    "  for i, j in df.iterrows():\n",
    "    for x in j:\n",
    "      if (abs(1-x) > 0.0000002):\n",
    "        mn = min(mn, x)\n",
    "        mx = max(mx, x)\n",
    "  return df.applymap(lambda x : (x-mn)/(mx-mn) if abs(1-x) > 0.0000002 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "njS0caebsWld",
    "outputId": "079375c1-726d-4382-d90e-c567e2e5e310"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(normalize(cosine_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "qEcHHw6irq6d",
    "outputId": "eefb4b81-5f0d-44e7-ae2a-5f7b462c696b"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(normalize(cosine_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvpEZlh_58JB"
   },
   "source": [
    "To give a bit of description on the playlist, it's a \"nostalgia\" playlist containing songs dating from the 60s even until the 00s. Hence, the songs in the playlist span different eras of music which  means that the songs may be very different in terms of words used and the themes of the songs. To illustrate this difference, we look at the similarities in language through the cosine similarity metric used below.\n",
    "\n",
    "Initially, the cosine similarity pairs for both BoW and TFIDF were very low, mostly within the range of 0.0 to 0.3. In a vacuum, this means that songs aren't really similar at all to each other, at least with respect to the lyrics of the songs. Again, the songs vary in terms of their release dates and thus their \"generations\", so the vocabulary and themes used vary, from friendly to romantic to breakup to even infatuation with a place.\n",
    "\n",
    "We can the BoW Heatmap has a slightly lighter tone than the TFIDF one, indicating slightly higher similarity scores. However, since we wanted to look at the relative similarities instead of looking at them in a vacuum, we decided to normalize these scores. After normalizing, we noticed that there were more _relatively_ similar pairs of songs in the BoW matrix, such as I Wanna Dance with Somebody by Whitney Houston and My Girl by The Temptations. This may be because of words used that are similar to each other or even words that appear in both songs in the pair. For example, \"hot\" was used in the former song while \"cold\" was used in the latter, while \"feel\" and \"way\" appeared in both songs. In a nutshell, the BoW has more relatively similar songs because they look at the words used without gauging their importance in the songs, so songs that use cloesly associated words may be similar.\n",
    "\n",
    "This is where TFIDF comes in. The heatmap for TFIDF looks terrible, however, but it's because the importance is looked at there. There are fewer relatively similar pairs of songs, and most of them still have a low cosine similarity score. Going back to our example of Whiteney Houston and The Temptations, this time the score is a lot lower because the similar words mention (hot, cold, feel, way) have differing importance in the two songs, or aren't even important at all (\"hot\" and \"cold\" are only mentioned once or twice in both songs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JV7VdaXXNUg"
   },
   "source": [
    "# Five Most Important Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfgSxw8XGQd0"
   },
   "source": [
    "You can find the 5 important words for each song below. We can see that most of the time, the words in the title, if these words aren't stopwords, are also found in the most important words. If not the title, the words in the chorus are found. This is because the chorus is the most repeated part of the song usually.\n",
    "\n",
    "As for being summaries, these words aren't enough still because a lot of these words should be stopwords (e.g. ooh, gogo, woah, im) even though they aren't, so these don't convey much meaning, if at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "crnT1qFlCKhp",
    "outputId": "19dafa7c-11b7-4a11-de87-62f4dac07703"
   },
   "outputs": [],
   "source": [
    "impt_df = pd.DataFrame(columns=['title', 'important_words'])\n",
    "for index, row in tfidf_df.iterrows():\n",
    "    impt_df.loc[index] = {\n",
    "      'title': playlist_dict[index][0],\n",
    "      'important_words': ' '.join(tfidf_df.iloc[index][tfidf_df.iloc[index] > 0].sort_values(ascending=False).head().index)\n",
    "  }\n",
    "\n",
    "impt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7iXsEUJq9CYL"
   },
   "source": [
    "# **Bonus**\n",
    "\n",
    "The following is a TF-IDF analysis of the top 5 songs of the band **Bread**. We identify the top 10 most important words and discuss an analysis of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rKaPLFX-evq6",
    "outputId": "04e57efd-29e0-4727-9d23-9d3c746ae56f"
   },
   "outputs": [],
   "source": [
    "# Searches for artist URI\n",
    "results = sp.search(\"artist:bread\")\n",
    "artist_id = results['tracks']['items'][0]['artists'][0]['uri']\n",
    "print(artist_id)\n",
    "\n",
    "#sp.artist_top_tracks(artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eeQ9proW9s0n",
    "outputId": "239e70e1-7495-419e-b303-6f46b4d1a768"
   },
   "outputs": [],
   "source": [
    "ARTIST_URI = 'spotify:artist:70ZTdbPEcEugBNay4MvxfL' # Artist URI of the band Bread\n",
    "ARTIST = 'Bread'\n",
    "TOP_SONGS = 5\n",
    "\n",
    "artist_tracks = sp.artist_top_tracks(ARTIST_URI)\n",
    "track_dict = {}\n",
    "\n",
    "for i, track in enumerate(artist_tracks['tracks'][:TOP_SONGS]):\n",
    "    title = track['name']\n",
    "    track_dict[i] = title\n",
    "\n",
    "print(track_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "VdXN9cSVeu-J",
    "outputId": "b1bf8e66-0254-46a8-a825-9fa2301df517"
   },
   "outputs": [],
   "source": [
    "# import lyricsgenius\n",
    "\n",
    "songs = track_dict\n",
    "lyrics_dict_2 = {}\n",
    "genius = lyricsgenius.Genius(\"lgrmQD5L0EqGrGCqmiXmHvizYtaDYeu5gAn0TRwD3FPEzE1WRL_Y2mBAZTdrMGB-\")\n",
    "\n",
    "for song in songs:\n",
    "    lyric = genius.search_song(songs[song], ARTIST)\n",
    "    #print(lyric.lyrics,\"\\n\")\n",
    "    lyrics_dict_2[songs[song]] = lyric.lyrics\n",
    "\n",
    "print(lyrics_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fqozGYX_fGCD",
    "outputId": "16f8167e-9396-4bce-9e4a-2dcf53e5b6af"
   },
   "outputs": [],
   "source": [
    "# Using functions from above, we use TF-IDF on the artist's top 5 song\n",
    "addtl_stopwords = ['chorus','verse','1','2','3','4','5']\n",
    "\n",
    "lines_from_dict = get_song_lines_from_dict(lyrics_dict_2)\n",
    "for i in lines_from_dict:\n",
    "  for j in i:\n",
    "    if j in addtl_stopwords:\n",
    "      i.remove(j)\n",
    "\n",
    "tfidf_df = tfidf(lines_from_dict)\n",
    "cosine_tfidf = cosine_similarity_matrix_tfidf(tfidf_df)\n",
    "cosine_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "xuI_wysyr0kj",
    "outputId": "c4f53deb-c4a7-4697-aea7-b355d11b3a9d"
   },
   "outputs": [],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-Pl_jLpIiaN"
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PJsRC-mL1lQ4",
    "outputId": "1cfa8647-9cac-41e8-ec49-8c365d59d296"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cosine_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "LnOn3vTwatYX",
    "outputId": "67202f14-b02c-4d1e-db77-baac977d2bb0"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(normalize(cosine_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKEhNFsw2LJI"
   },
   "source": [
    "\n",
    "Bread is a 70's soft rock band. Most of their songs, at least in the lyrics, capture the 70's culture. Using Spotify's API, we retrieved the band's five most popular songs, and mined each songs' lyrics from Genius.com. \n",
    "\n",
    "We used TF-IDF to analyze the songs' lyrics and came up with a similar looking heatmap as the ones used from the playlist analysis. Obviously, the lyrics of the songs don't quite look similar with each other, as the cosine similarity pairs for TF-IDF were very low. This isn't surprising since an artist would most probably write different songs depending on its topic and that no two songs are inherently similar, lyrics-wise. Making songs with similar topics and word content would make the artist bland.\n",
    "\n",
    "Much like we did previously, normalizing the cosine similarity lightened the tone of the heatmap. This means that some songs became more 'similar' to certain songs, such as *Everything I Own* and *If*. \n",
    "\n",
    "Below is the normalized TF-IDF matrix for the top 5 songs from Bread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kgDYaausg1e6",
    "outputId": "7442e5cd-d2b6-4202-ef26-2d5a188f2bdb"
   },
   "outputs": [],
   "source": [
    "normalize(cosine_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ER2WmYc2pEc"
   },
   "source": [
    "### Top 10 words\n",
    "\n",
    "Given below are the most common words per song. This however won't effectively give us a glimpse of the most important words if the top 5 songs were aggregated. Thus, in the next cell, we see gather the 10 words with the greatest summed TF-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ywNHIt5v2svy",
    "outputId": "ee406ded-cf4b-4b51-d259-b54ad6122294"
   },
   "outputs": [],
   "source": [
    "# Most important words for each song\n",
    "\n",
    "impt_df = pd.DataFrame(columns=['title', 'important_words'])\n",
    "for index, row in tfidf_df.iterrows():\n",
    "    impt_df.loc[index] = {\n",
    "        'title': track_dict[index],\n",
    "        'important_words': ', '.join(tfidf_df.iloc[index][tfidf_df.iloc[index] > 0].sort_values(ascending=False).head(10).index)\n",
    "    }\n",
    "\n",
    "impt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "TKhPJd5jXXjL",
    "outputId": "953a3249-b339-472b-d989-99e2d66d2cc9"
   },
   "outputs": [],
   "source": [
    "# 10 most important words for the top 5 songs\n",
    "from collections import Counter\n",
    "\n",
    "impt_dict = {}\n",
    "for (colName, colData) in tfidf_df.iteritems():\n",
    "    impt_dict[colName] = colData.sum()\n",
    "\n",
    "top = Counter(impt_dict)\n",
    "top.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1d595PXIqYt"
   },
   "source": [
    "The top 10 words of Bread's top 5 songs were given above. The top word \"I'm-a\", spelled here as *'ima'*, only appeared in the song *Baby I'm-a Want You* although it appeared in that song many times. The other words appeared in 2 or more songs and are given much more importance than any other words given their aggregated TF-IDF scores. Unsuprisingly, some of these words are already found in their respective song's titles or within the choruses of certain songs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cs179_ps3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
